apiVersion: v1
kind: ConfigMap
metadata:
  name: production-alerts
  namespace: default
  labels:
    tier: production
    monitoring: enabled
data:
  # Production monitoring alerts
  production-alerts.yml: |
    groups:
    # Production Security Alerts
    - name: production-security
      interval: 30s
      rules:
      
      - alert: SecurityPolicyViolation
        expr: increase(security_events_total{event_type="policy_violation"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
          team: security
          tier: production
        annotations:
          summary: "Security policy violation detected"
          description: "{{ $value }} security policy violations in the last 5 minutes"
          runbook_url: "https://runbooks.company.com/security/policy-violation"
          
      - alert: UnauthorizedAccess
        expr: increase(security_events_total{event_type="unauthorized_access"}[5m]) > 3
        for: 2m
        labels:
          severity: warning
          team: security
          tier: production
        annotations:
          summary: "Multiple unauthorized access attempts"
          description: "{{ $value }} unauthorized access attempts detected"
          runbook_url: "https://runbooks.company.com/security/unauthorized-access"
          
      - alert: NetworkPolicyViolation
        expr: increase(security_events_total{event_type="network_policy_violation"}[10m]) > 0
        for: 1m
        labels:
          severity: warning
          team: sre
          tier: production
        annotations:
          summary: "Network policy violation detected"
          description: "Network traffic blocked by security policies"
          
    # Production Cost Alerts  
    - name: production-cost
      interval: 300s
      rules:
      
      - alert: ResourceWastage
        expr: |
          (
            sum(container_spec_memory_limit_bytes{pod=~"sre-demo-app-.*"}) -
            sum(container_memory_working_set_bytes{pod=~"sre-demo-app-.*"})
          ) / sum(container_spec_memory_limit_bytes{pod=~"sre-demo-app-.*"}) * 100 > 40
        for: 15m
        labels:
          severity: warning
          team: sre
          tier: production
          cost_impact: high
        annotations:
          summary: "High resource wastage detected"
          description: "{{ $value }}% of allocated memory is unused"
          runbook_url: "https://runbooks.company.com/cost/resource-optimization"
          
      - alert: CostThresholdExceeded
        expr: sum(cluster_cost_hourly) > 10
        for: 30m
        labels:
          severity: warning
          team: finops
          tier: production
          cost_impact: critical
        annotations:
          summary: "Hourly cost threshold exceeded"
          description: "Current cluster cost: ${{ $value }}/hour"
          runbook_url: "https://runbooks.company.com/cost/threshold-exceeded"
          
      - alert: AutoscalingInefficiency
        expr: |
          (
            kube_horizontalpodautoscaler_status_current_replicas{horizontalpodautoscaler="sre-demo-hpa-optimized"} /
            kube_horizontalpodautoscaler_spec_max_replicas{horizontalpodautoscaler="sre-demo-hpa-optimized"}
          ) > 0.8
        for: 1h
        labels:
          severity: info
          team: sre
          tier: production
        annotations:
          summary: "Autoscaling near maximum capacity"
          description: "HPA using {{ $value }}% of maximum replicas for extended period"
          
    # Production Reliability Alerts
    - name: production-reliability
      interval: 30s
      rules:
      
      - alert: ProductionServiceDown
        expr: up{job="sre-demo-app",tier="production"} == 0
        for: 30s
        labels:
          severity: critical
          team: sre
          tier: production
          escalation: immediate
        annotations:
          summary: "Production service completely down"
          description: "Production SRE demo service is unreachable"
          runbook_url: "https://runbooks.company.com/incidents/service-down"
          
      - alert: ProductionHighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status_code=~"5..",tier="production"}[5m])) /
            sum(rate(http_requests_total{tier="production"}[5m]))
          ) * 100 > 2
        for: 3m
        labels:
          severity: critical
          team: sre
          tier: production
        annotations:
          summary: "Production error rate above threshold"
          description: "Error rate: {{ $value }}% (threshold: 2%)"
          runbook_url: "https://runbooks.company.com/incidents/high-error-rate"
          
      - alert: ProductionLatencyDegradation
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket{tier="production"}[5m])) by (le)
          ) > 0.5
        for: 5m
        labels:
          severity: warning
          team: sre
          tier: production
        annotations:
          summary: "Production latency degraded"
          description: "P95 latency: {{ $value }}s (threshold: 0.5s)"
          runbook_url: "https://runbooks.company.com/performance/latency"
          
      - alert: ProductionReplicasMismatch
        expr: |
          kube_deployment_status_replicas{deployment="sre-demo-app"} != 
          kube_deployment_status_ready_replicas{deployment="sre-demo-app"}
        for: 10m
        labels:
          severity: warning
          team: sre
          tier: production
        annotations:
          summary: "Production replica count mismatch"
          description: "Desired replicas != Ready replicas for 10+ minutes"
          
    # Production Backup and DR Alerts
    - name: production-backup
      interval: 3600s  # Check hourly
      rules:
      
      - alert: BackupJobFailed
        expr: |
          kube_job_status_failed{job_name=~"database-backup.*"} > 0
        for: 5m
        labels:
          severity: critical
          team: sre
          tier: production
          data_impact: high
        annotations:
          summary: "Production backup job failed"
          description: "Database backup job {{ $labels.job_name }} failed"
          runbook_url: "https://runbooks.company.com/backup/job-failure"
          
      - alert: BackupNotExecuted
        expr: |
          (time() - kube_job_status_completion_time{job_name=~"database-backup.*"}) > 172800
        for: 1h
        labels:
          severity: warning
          team: sre
          tier: production
          data_impact: medium
        annotations:
          summary: "Backup not executed within SLA"
          description: "No successful backup in last 48 hours"
          runbook_url: "https://runbooks.company.com/backup/sla-violation"
          
      - alert: DisasterRecoveryTestOverdue
        expr: |
          (time() - kube_job_status_completion_time{job_name=~"dr-test.*"}) > 604800
        for: 1d
        labels:
          severity: info
          team: sre
          tier: production
        annotations:
          summary: "Disaster recovery test overdue"
          description: "No DR test executed in last 7 days"
          
    # Production Compliance Alerts
    - name: production-compliance
      interval: 3600s
      rules:
      
      - alert: ComplianceViolation
        expr: |
          sum(security_events_total{event_type="compliance_violation"}) > 0
        for: 1m
        labels:
          severity: critical
          team: compliance
          tier: production
          regulatory_impact: high
        annotations:
          summary: "Compliance violation detected"
          description: "Regulatory compliance violation in production environment"
          runbook_url: "https://runbooks.company.com/compliance/violation"
          
      - alert: AuditLogFailure
        expr: |
          increase(kube_pod_container_status_restarts_total{pod=~"audit-log.*"}[1h]) > 0
        for: 5m
        labels:
          severity: warning
          team: security
          tier: production
        annotations:
          summary: "Audit logging service restarted"
          description: "Audit log pod restarted - potential compliance impact"
          
      - alert: ResourceQuotaExceeded
        expr: |
          kube_resourcequota{resource="requests.memory",type="used"} /
          kube_resourcequota{resource="requests.memory",type="hard"} > 0.9
        for: 15m
        labels:
          severity: warning
          team: sre
          tier: production
        annotations:
          summary: "Resource quota nearly exceeded"
          description: "{{ $value }}% of memory quota utilized"

  # Production alert routing
  production-routing.yml: |
    # Production Alert Routing Rules
    
    route:
      group_by: ['tier', 'severity', 'team']
      group_wait: 10s
      group_interval: 30s
      repeat_interval: 30m
      receiver: 'production-default'
      routes:
      
      # Critical production alerts
      - matchers:
        - tier="production"
        - severity="critical"
        receiver: 'production-critical'
        group_wait: 0s
        repeat_interval: 5m
        continue: true
        
      # Security alerts
      - matchers:
        - team="security"
        - tier="production"
        receiver: 'security-team'
        group_wait: 30s
        repeat_interval: 15m
        
      # Cost optimization alerts
      - matchers:
        - cost_impact=~"high|critical"
        - tier="production"
        receiver: 'finops-team'
        group_wait: 5m
        repeat_interval: 4h
        
      # Data/backup alerts
      - matchers:
        - data_impact=~"high|medium"
        - tier="production"
        receiver: 'data-team'
        group_wait: 2m
        repeat_interval: 1h
        
      # Compliance alerts
      - matchers:
        - regulatory_impact="high"
        - tier="production"
        receiver: 'compliance-team'
        group_wait: 0s
        repeat_interval: 15m
    
    receivers:
    - name: 'production-default'
      slack_configs:
      - api_url: 'SLACK_WEBHOOK_URL'
        channel: '#production-alerts'
        
    - name: 'production-critical'
      pagerduty_configs:
      - routing_key: 'PAGERDUTY_INTEGRATION_KEY'
        description: '{{ .CommonAnnotations.summary }}'
      slack_configs:
      - api_url: 'SLACK_WEBHOOK_URL'
        channel: '#production-critical'
        
    - name: 'security-team'
      email_configs:
      - to: 'security-team@company.com'
        subject: '🔒 Security Alert - {{ .CommonAnnotations.summary }}'
        
    - name: 'finops-team'
      slack_configs:
      - api_url: 'SLACK_WEBHOOK_URL'
        channel: '#finops-alerts'
        
    - name: 'data-team'
      email_configs:
      - to: 'data-team@company.com'
        subject: '💾 Data/Backup Alert - {{ .CommonAnnotations.summary }}'
        
    - name: 'compliance-team'
      email_configs:
      - to: 'compliance-team@company.com'
        subject: '⚖️ URGENT Compliance Alert - {{ .CommonAnnotations.summary }}'
      pagerduty_configs:
      - routing_key: 'COMPLIANCE_PAGERDUTY_KEY'

    # Inhibition rules for production
    inhibit_rules:
    - source_matchers:
      - severity="critical"
      - tier="production"
      target_matchers:
      - severity=~"warning|info"
      - tier="production"
      equal: ['team', 'service']
      
    - source_matchers:
      - alertname="ProductionServiceDown"
      target_matchers:
      - tier="production"
      equal: ['service']