---
# Velero backup configuration for disaster recovery
apiVersion: v1
kind: Namespace
metadata:
  name: velero
  labels:
    disaster-recovery: "enabled"

---
apiVersion: velero.io/v1
kind: BackupStorageLocation
metadata:
  name: production-backup-location
  namespace: velero
  labels:
    disaster-recovery: "enabled"
spec:
  provider: gcp
  objectStorage:
    bucket: sre-demo-backup-production
    prefix: kubernetes-backups
  config:
    serviceAccount: velero-backup-service@PROJECT_ID.iam.gserviceaccount.com

---
apiVersion: velero.io/v1
kind: VolumeSnapshotLocation
metadata:
  name: production-snapshot-location
  namespace: velero
  labels:
    disaster-recovery: "enabled"
spec:
  provider: gcp
  config:
    project: PROJECT_ID

---
# Scheduled backup for application data
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: sre-demo-daily-backup
  namespace: velero
  labels:
    disaster-recovery: "enabled"
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  template:
    metadata:
      labels:
        backup-type: daily
        app: sre-demo-app
    spec:
      includedNamespaces:
      - default
      - monitoring
      includedResources:
      - deployments
      - services
      - configmaps
      - secrets
      - persistentvolumes
      - persistentvolumeclaims
      labelSelector:
        matchLabels:
          app: sre-demo-app
      storageLocation: production-backup-location
      volumeSnapshotLocations:
      - production-snapshot-location
      ttl: 720h0m0s  # 30 days retention

---
# Weekly full cluster backup
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: sre-demo-weekly-backup
  namespace: velero
  labels:
    disaster-recovery: "enabled"
spec:
  schedule: "0 3 * * 0"  # Weekly on Sunday at 3 AM
  template:
    metadata:
      labels:
        backup-type: weekly-full
    spec:
      includedNamespaces: []  # All namespaces
      storageLocation: production-backup-location
      volumeSnapshotLocations:
      - production-snapshot-location
      ttl: 2160h0m0s  # 90 days retention

---
# Backup monitoring and alerting
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-monitoring
  namespace: velero
  labels:
    disaster-recovery: "enabled"
data:
  backup-queries.yaml: |
    # Backup monitoring queries
    backup_success_rate: |
      sum(rate(velero_backup_success_total[24h])) /
      sum(rate(velero_backup_total[24h])) * 100
    
    backup_duration: |
      velero_backup_duration_seconds
      
    backup_size: |
      velero_backup_size_bytes
      
    failed_backups: |
      sum(rate(velero_backup_failure_total[24h]))
      
    restore_duration: |
      velero_restore_duration_seconds

---
# Multi-region replication configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: multi-region-dr-config
  namespace: default
  labels:
    disaster-recovery: "enabled"
data:
  disaster-recovery.yaml: |
    # Multi-region disaster recovery configuration
    primary_region: us-central1
    secondary_regions:
      - us-west1
      - europe-west1
    
    replication_policy:
      rpo: 4h  # Recovery Point Objective
      rto: 30m # Recovery Time Objective
      
    backup_schedule:
      local_backup: "0 */6 * * *"    # Every 6 hours
      cross_region: "0 1 * * *"      # Daily cross-region
      
    failover_triggers:
      - region_unavailable
      - rto_exceeded
      - manual_activation

---
# Persistent Volume backup policy
apiVersion: v1
kind: ConfigMap
metadata:
  name: pv-backup-policy
  namespace: default
  labels:
    disaster-recovery: "enabled"
data:
  pv-policy.yaml: |
    # Persistent Volume backup policies
    storage_classes:
      - name: ssd-backup
        backup_schedule: "0 */4 * * *"
        retention_days: 30
        cross_region: true
        
      - name: standard-backup
        backup_schedule: "0 2 * * *"
        retention_days: 7
        cross_region: false

---
# Database backup configuration
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
  namespace: default
  labels:
    disaster-recovery: "enabled"
spec:
  schedule: "0 1 * * *"  # Daily at 1 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: gcr.io/PROJECT_ID/backup-tools:latest
            command:
            - /bin/bash
            - -c
            - |
              # Database backup script
              export BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
              export BACKUP_FILE="sre-demo-db-backup-${BACKUP_DATE}.sql"
              
              # Create backup
              pg_dump $DATABASE_URL > /tmp/$BACKUP_FILE
              
              # Upload to cloud storage
              gsutil cp /tmp/$BACKUP_FILE gs://sre-demo-backup-production/database/
              
              # Verify backup
              gsutil ls -l gs://sre-demo-backup-production/database/$BACKUP_FILE
              
              # Cleanup old backups (keep 30 days)
              gsutil ls gs://sre-demo-backup-production/database/ | \
                grep -E "[0-9]{8}_[0-9]{6}" | \
                head -n -30 | \
                gsutil -m rm -I
            env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: database-credentials
                  key: url
            volumeMounts:
            - name: backup-temp
              mountPath: /tmp
          volumes:
          - name: backup-temp
            emptyDir: {}
          restartPolicy: OnFailure

---
# Disaster recovery testing
apiVersion: batch/v1
kind: CronJob
metadata:
  name: dr-test
  namespace: default
  labels:
    disaster-recovery: "enabled"
spec:
  schedule: "0 4 * * 6"  # Weekly on Saturday at 4 AM
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            job-type: disaster-recovery-test
        spec:
          containers:
          - name: dr-test
            image: gcr.io/PROJECT_ID/dr-test-tools:latest
            command:
            - /bin/bash
            - -c
            - |
              # DR test automation
              echo "Starting DR test at $(date)"
              
              # Test backup integrity
              velero backup get --selector backup-type=daily
              
              # Test restore in secondary region
              kubectl config use-context gke_PROJECT_ID_us-west1_sre-demo-cluster-dr
              
              # Create test namespace
              kubectl create namespace dr-test-$(date +%s) --dry-run=client -o yaml | kubectl apply -f -
              
              # Perform test restore
              velero restore create dr-test-$(date +%s) \
                --from-backup sre-demo-daily-backup-$(date +%Y%m%d) \
                --namespace-mappings default:dr-test-$(date +%s)
              
              # Validate restore success
              kubectl wait --for=condition=available --timeout=300s deployment/sre-demo-app -n dr-test-$(date +%s)
              
              # Cleanup test namespace
              kubectl delete namespace dr-test-$(date +%s) --wait=false
              
              echo "DR test completed successfully at $(date)"
            env:
            - name: VELERO_NAMESPACE
              value: velero
          restartPolicy: OnFailure
          serviceAccountName: velero-dr-test

---
# Recovery procedures documentation
apiVersion: v1
kind: ConfigMap
metadata:
  name: recovery-procedures
  namespace: default
  labels:
    disaster-recovery: "enabled"
data:
  recovery-runbook.md: |
    # Disaster Recovery Runbook
    
    ## Recovery Scenarios
    
    ### Scenario 1: Application Pod Failure
    - Detection: Pod restart loops, health check failures
    - Recovery: kubectl rollout restart deployment/sre-demo-app
    - Validation: Check pod status and health endpoints
    
    ### Scenario 2: Persistent Volume Data Loss
    - Detection: Data inconsistency, mount failures
    - Recovery: Restore from latest PV snapshot
    - Command: velero restore create --from-backup [backup-name]
    - Validation: Data integrity checks
    
    ### Scenario 3: Region-Wide Outage
    - Detection: Region unavailable, cross-region monitoring alerts
    - Recovery: Activate secondary region deployment
    - Steps:
      1. Update DNS to point to secondary region
      2. Restore latest backup in secondary region
      3. Scale up secondary region deployment
      4. Validate application functionality
    
    ### Scenario 4: Complete Cluster Loss
    - Detection: Cluster unreachable, all nodes down
    - Recovery: Full cluster restoration from backups
    - Steps:
      1. Provision new GKE cluster
      2. Install Velero and restore infrastructure
      3. Restore application data from backups
      4. Update external dependencies
      5. Comprehensive validation testing
    
    ## Recovery Time Objectives
    - Application restart: 5 minutes
    - PV restore: 15 minutes
    - Cross-region failover: 30 minutes
    - Full cluster restore: 2 hours